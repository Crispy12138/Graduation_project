{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNRKoCQEoiOqrDqqMg8lAW4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Crispy12138/Graduation_project/blob/main/Encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLN7mRIrMOsV",
        "outputId": "84c13b75-1e51-4860-bfd6-1f4d8041b251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, MultiHeadAttention, LayerNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# Parameters from Table 1\n",
        "T10 = 300  # K\n",
        "F10 = 5    # m^3/h\n",
        "V1 = 1     # m^3\n",
        "T1s = 402  # K\n",
        "CA1s = 1.95  # kmol/m^3\n",
        "CA10s = 4    # kmol/m^3\n",
        "Q1s = 0.0  # kJ/hr\n",
        "k0 = 8.46e6  # m^3/kmol h\n",
        "Cp = 0.231  # kJ/kg K\n",
        "rhoL = 1000 # kg/m^3\n",
        "R = 8.314  # kJ/kmol K\n",
        "E = 5e4    # kJ/kmol\n",
        "DeltaH = -1.15e4  # kJ/kmol\n",
        "\n",
        "T20 = 300  # K\n",
        "F20 = 5    # m^3/h\n",
        "V2 = 1     # m^3\n",
        "T2s = 402  # K\n",
        "CA2s = 1.95  # kmol/m^3\n",
        "CA20s = 4    # kmol/m^3\n",
        "Q2s = 0.0  # kJ/hr\n",
        "\n",
        "\n",
        "delta_CA0_min , delta_CA0_max=  -3.5, 3.5\n",
        "delta_Q_min ,delta_Q_max = -5e5, 5e5\n",
        "delta_CA_min ,delta_CA_max = -1.95, 2\n",
        "delta_T_min , delta_T_max = -100, 100\n",
        "\n",
        "# defination of Lyapunov function V(x) = xTPx\n",
        "P = np.mat([[1060,22],[22,0.52]])\n",
        "rou = 380.0\n",
        "\n",
        "# filter points of x within the ellipse\n",
        "def x_calculator (initial_number,r):\n",
        "    x_list = []\n",
        "    conc = np.linspace(delta_CA_min, delta_CA_max, initial_number)\n",
        "    temp = np.linspace(delta_T_min,  delta_T_max,  initial_number)\n",
        "    for i in range(conc.size):\n",
        "        for j in range(temp.size):\n",
        "            x = np.array([[conc[i]],[temp[j]]])\n",
        "            Vx = x.T @ P @ x\n",
        "            if Vx <= r:\n",
        "                x_list.append(x.flatten())\n",
        "    final_x = np.array(x_list).T\n",
        "    return final_x\n",
        "\n",
        "# disrupt x points -> x points of CSTR 2\n",
        "def x_transform(x1):\n",
        "    x2 = x1.copy().T\n",
        "    np.random.shuffle(x2)\n",
        "    x2=x2.T\n",
        "    return x2\n",
        "\n",
        "# calculate the raw values of input\n",
        "def XY_calculator(h,time_step,x01,x02,number_of_point):\n",
        "\n",
        "    delta_CA10 =np.linspace(delta_CA0_min,delta_CA0_max, number_of_point)\n",
        "    delta_CA20 =x_transform(delta_CA10)\n",
        "\n",
        "    delta_Q1   =np.linspace(delta_Q_min , delta_Q_max,   number_of_point)\n",
        "    delta_Q2   =x_transform(delta_Q1)\n",
        "    t = np.arange(0,(time_step*h),h)\n",
        "\n",
        "    X = np.zeros((number_of_point,time_step,8))\n",
        "    Y = np.zeros((number_of_point,time_step,4))\n",
        "\n",
        "    for i in range(number_of_point):\n",
        "\n",
        "        CA1 = x01[0][i] + CA1s\n",
        "        T1 = x01[1][i] + T1s\n",
        "        CA2 = x02[0][i] + CA2s\n",
        "        T2 = x02[1][i] + T2s\n",
        "\n",
        "        CA10 = delta_CA10[i] + CA10s\n",
        "        Q1 = delta_Q1[i] + Q1s\n",
        "        CA20 = delta_CA20[i] + CA20s\n",
        "        Q2 = delta_Q2[i] + Q2s\n",
        "\n",
        "        for j in range(time_step):\n",
        "            X[i,j] = [x01[0][i], x01[1][i], x02[0][i], x02[1][i], \\\n",
        "                      delta_CA10[i], delta_Q1[i],delta_CA20[i], delta_Q2[i]]\n",
        "            Y[i,j] = [CA1-CA1s, T1-T1s , CA2-CA2s, T2-T2s]\n",
        "            r1 = k0 * np.exp(-E / (R * T1)) * CA1**2\n",
        "            r2 = k0 * np.exp(-E / (R * T2)) * CA2**2\n",
        "            CA1+= h * ((F10 / V1) * (CA10 - CA1) - r1)\n",
        "            T1 += h * ((F10 / V1) * (T10 - T1) + (-DeltaH * r1) / (rhoL * Cp) + Q1 / (rhoL * Cp * V1))\n",
        "            CA2+= h * ((F20 / V2) * CA20 + (F10 / V2) * CA1 - (F10 + F20) / V2 * CA2 - r2)\n",
        "            T2 += h * ((F20 / V2) * T20 + (F10 / V2) * T1 - (F10 + F20) / V2 * T2 + (-DeltaH * r2) / (rhoL * Cp) + Q2s / (rhoL * Cp * V2))\n",
        "\n",
        "    return X,Y\n"
      ],
      "metadata": {
        "id": "_xJ4xep2MSFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x01 = x_calculator(1000,rou)\n",
        "x02 = x_transform(x01)\n",
        "\n",
        "print(x02.shape)\n",
        "print(x01.shape)\n",
        "print(x01)\n",
        "print(x02)\n",
        "\n",
        "h = 1e-3\n",
        "time_step=100\n",
        "\n",
        "number_of_point = np.size(x01,1)\n",
        "X,Y = XY_calculator(h,time_step,x01,x02,number_of_point)\n",
        "print(f\"shape of X:{np.shape(X)}\")\n",
        "print(f\"shape of Y:{np.shape(Y)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VjbRIK8L8e7",
        "outputId": "391c215a-9d47-4f12-9a78-c2288d52be8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 183969)\n",
            "(2, 183969)\n",
            "[[ -1.71276276  -1.71276276  -1.71276276 ...   1.71136136   1.71136136\n",
            "    1.71136136]\n",
            " [ 71.17117117  71.37137137  71.57157157 ... -71.17117117 -70.97097097\n",
            "  -70.77077077]]\n",
            "[[-6.21471471e-01 -1.25625626e-02  2.99799800e-01 ... -1.48343343e+00\n",
            "  -4.35635636e-01  1.07082082e+00]\n",
            " [ 1.07107107e+01 -7.90790791e+00 -1.43143143e+01 ...  7.47747748e+01\n",
            "   1.03103103e+01 -6.63663664e+01]]\n",
            "shape of X:(183969, 100, 8)\n",
            "shape of Y:(183969, 100, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "scaler_X = preprocessing.StandardScaler().fit(X.reshape(-1, 8))\n",
        "scaler_y = preprocessing.StandardScaler().fit(Y.reshape(-1, 4))\n",
        "\n",
        "RNN_input = scaler_X.transform(X.reshape(-1, 8)).reshape(-1,10,8)\n",
        "RNN_output = scaler_y.transform(Y.reshape(-1, 4)).reshape(-1,10,4)\n",
        "\n",
        "'''print(\"RNN_input shape is {}\".format(RNN_input.shape))\n",
        "print(\"RNN_output shape is {}\".format(RNN_output.shape))'''\n",
        "X_train, X_test, y_train, y_test = train_test_split(RNN_input, RNN_output, test_size=0.3, random_state=123)\n",
        "\n",
        "\n",
        "print(f\"scaler_X_mean= {scaler_X.mean_}\")\n",
        "print(f\"scaler_X.var_={scaler_X.var_}\")\n",
        "print(f\"scaler_y.mean_={scaler_y.mean_}\")\n",
        "print(f\"scaler_y.var_={scaler_y.var_}\")\n",
        "\n",
        "\n",
        "# checking X_train\n",
        "np.save('X_train.npy',X_train)\n",
        "np.save('X_test.npy',X_test)\n",
        "np.save('y_train.npy',y_train)\n",
        "np.save('y_test.npy',y_test)\n",
        "np.save('X_mean.npy',scaler_X.mean_)\n",
        "np.save('X_std.npy',np.sqrt(scaler_X.var_))\n",
        "np.save('y_mean.npy',scaler_y.mean_)\n",
        "np.save('y_std.npy',np.sqrt(scaler_y.var_))\n",
        "X_train = np.load('X_train.npy')\n",
        "X_test = np.load('X_test.npy')\n",
        "y_train = np.load('y_train.npy')\n",
        "y_test = np.load('y_test.npy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXexmd4QMHv-",
        "outputId": "b6230969-ec9f-4c6e-9151-5ed444e1bfb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scaler_X_mean= [-9.97469659e-06  1.99417764e-03 -9.97469702e-06  1.99417764e-03\n",
            "  1.77480227e-17 -1.40483310e-11 -7.76436926e-15 -1.43072114e-10]\n",
            "scaler_X.var_=[7.35129844e-01 1.49855399e+03 7.35129844e-01 1.49855399e+03\n",
            " 4.08337773e+00 8.33342393e+10 4.08337773e+00 8.33342393e+10]\n",
            "scaler_y.mean_=[-0.46500459 23.16266499 -0.0720231   3.59869366]\n",
            "scaler_y.var_=[7.82186684e-01 9.63372262e+03 5.82574227e-01 1.64912204e+03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dim_feedforward, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.attention = tf.keras.layers.MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(dim_feedforward, activation='relu'),\n",
        "            Dense(d_model)\n",
        "        ])\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attn_output = self.attention(inputs, inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = out1 + ffn_output\n",
        "        return self.layernorm2(ffn_output)\n",
        "\n",
        "\n",
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                            np.arange(d_model)[np.newaxis, :],\n",
        "                            d_model)\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    pos_encoding = angle_rads[np.newaxis]\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "def build_transformer_model(input_shape, output_shape, d_model, num_heads, dim_feedforward):\n",
        "    original_inputs = Input(shape=input_shape)\n",
        "    position, _ = input_shape\n",
        "    projection_layer = tf.keras.layers.Dense(units=d_model, activation='linear')\n",
        "    projected_inputs = projection_layer(original_inputs)\n",
        "    inputs_with_pe = positional_encoding(position, d_model) + projected_inputs\n",
        "    transformer_layer = EncoderLayer(d_model, num_heads, dim_feedforward)\n",
        "    x = transformer_layer(inputs_with_pe)\n",
        "   # print(f\"y in transformer_layer={y}\")\n",
        "    x = Dense(output_shape)(x)\n",
        "    model = Model(original_inputs, x)\n",
        "    return model\n",
        "\n",
        "model = build_transformer_model(\n",
        "    input_shape=(10, 8),\n",
        "    output_shape=(4),\n",
        "    d_model=64,\n",
        "    num_heads=8,\n",
        "    dim_feedforward=512\n",
        ")\n",
        "\n",
        "initial_learning_rate = 0.0001\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=100000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True)\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=50, min_delta=1e-6, restore_best_weights=True)\n",
        "model.compile(adam,loss=MeanSquaredError())\n",
        "\n",
        "start_time = time.time()\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=500,\n",
        "    batch_size=256,\n",
        "    validation_split=0.1,\n",
        "    callbacks=early_stopping\n",
        ")\n",
        "end_time = time.time()\n",
        "total_training_time = end_time - start_time\n",
        "print(f\"total training time ={total_training_time}\")\n",
        "\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(model.evaluate(X_test,y_test))\n",
        "tf.saved_model.save(model, 'my_model_saved2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "4YmgZtJSMKra",
        "outputId": "a52ec7fa-ca46-42af-eba9-54fc105c2481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "4528/4528 [==============================] - 64s 13ms/step - loss: 0.3958 - val_loss: 0.3836\n",
            "Epoch 2/500\n",
            "4528/4528 [==============================] - 57s 13ms/step - loss: 0.3842 - val_loss: 0.3819\n",
            "Epoch 3/500\n",
            "4528/4528 [==============================] - 57s 13ms/step - loss: 0.3835 - val_loss: 0.3815\n",
            "Epoch 4/500\n",
            "4528/4528 [==============================] - 56s 12ms/step - loss: 0.3832 - val_loss: 0.3814\n",
            "Epoch 5/500\n",
            "4528/4528 [==============================] - 57s 13ms/step - loss: 0.3829 - val_loss: 0.3815\n",
            "Epoch 6/500\n",
            "4528/4528 [==============================] - 57s 13ms/step - loss: 0.3828 - val_loss: 0.3806\n",
            "Epoch 7/500\n",
            "4528/4528 [==============================] - 57s 13ms/step - loss: 0.3827 - val_loss: 0.3812\n",
            "Epoch 8/500\n",
            "4528/4528 [==============================] - 57s 13ms/step - loss: 0.3826 - val_loss: 0.3811\n",
            "Epoch 9/500\n",
            "4528/4528 [==============================] - 57s 13ms/step - loss: 0.3825 - val_loss: 0.3808\n",
            "Epoch 10/500\n",
            "4528/4528 [==============================] - 56s 12ms/step - loss: 0.3824 - val_loss: 0.3812\n",
            "Epoch 11/500\n",
            "4528/4528 [==============================] - 57s 13ms/step - loss: 0.3824 - val_loss: 0.3810\n",
            "Epoch 12/500\n",
            "2126/4528 [=============>................] - ETA: 28s - loss: 0.3814"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a000593af02b>\u001b[0m in \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    136\u001b[0m   \u001b[0;31m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\u001b[0m in \u001b[0;36munpack_inputs\u001b[0;34m(self, bound_parameters)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_parameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m       flat.extend(\n\u001b[0;32m--> 391\u001b[0;31m           \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_constraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m       )\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36mto_tensors\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     nest.map_structure(\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mlambda\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_component_specs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mwrong\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m   \"\"\"\n\u001b[0;32m--> 631\u001b[0;31m   return nest_util.map_structure(\n\u001b[0m\u001b[1;32m    632\u001b[0m       \u001b[0mnest_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1064\u001b[0m   \"\"\"\n\u001b[1;32m   1065\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_core_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_data_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m   return _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1104\u001b[0m   return _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(spec, v)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     nest.map_structure(\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mlambda\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_component_specs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         self._to_components(value))\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor.py\u001b[0m in \u001b[0;36mto_tensors\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mto_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInternalCastContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_subtype_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m       raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(self, value, casting_context)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_conversion_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m     \u001b[0mvalue_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalue_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_subtype_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mdtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;31m# Note: using the intern table directly here as this is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;31m# performance-sensitive in some models.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_INTERN_TABLE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datatype_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.evaluate(X_test,y_test))\n",
        "model.load(my_model_saved)\n",
        "\n",
        "X_train = np.load('X_train.npy')\n",
        "X_test = np.load('X_test.npy')\n",
        "y_train = np.load('y_train.npy')\n",
        "y_test = np.load('y_test.npy')\n",
        "\n",
        "y_predict = model.predict(X_test)\n",
        "y_predict_2d = y_predict.reshape(-1, y_predict.shape[-1])\n",
        "y_predict_inversed = scaler_y.inverse_transform(y_predict_2d)\n",
        "y_predict = y_predict_inversed.reshape(y_predict.shape)\n",
        "print(y_predict)\n",
        "\n",
        "\n",
        "y_test_2d = y_test.reshape(-1, y_test.shape[-1])\n",
        "y_test_inversed = scaler_y.inverse_transform(y_test_2d)\n",
        "y_test = y_test_inversed.reshape(y_test.shape)\n",
        "print(y_test)\n",
        "\n",
        "\n",
        "\n",
        "X_test_2d = X_test.reshape(-1, X_test.shape[-1])\n",
        "X_plot_2d = scaler_X.inverse_transform(X_test_2d)\n",
        "X_plot = X_plot_2d.reshape(X_test.shape)\n",
        "\n",
        "y = np.linspace(-100, 100, 100000, endpoint=True)\n",
        "\n",
        "x_upper = list()\n",
        "x_lower = list()\n",
        "y_plot = list()\n",
        "\n",
        "for i in y:\n",
        "    sqrt = np.sqrt(-2688000 * i**2 + 15772800000)\n",
        "    if sqrt >= 0:\n",
        "        y_plot.append(i)\n",
        "        x_upper.append((-4400 * i + sqrt) / 212000)\n",
        "        x_lower.append((-4400 * i - sqrt) / 212000)\n",
        "        pass\n",
        "    pass\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "for i in range(10):\n",
        "    if i == 0:  # only add label to 1 data point\n",
        "        plt.plot(X_plot[i, 0, 0], X_plot[i, 0, 1], marker=\"*\", markersize=15, color='blue')\n",
        "        plt.plot(y_test[i, :, 0], y_test[i, :, 1], color='cyan', lw=2, label='CSTR1_Test')\n",
        "        plt.plot(y_predict[i, :, 0], y_predict[i, :, 1], color='black', lw=2, ls=':', label='CSTR1_Predicted')\n",
        "        plt.plot(X_plot[i, 0, 2], X_plot[i, 0, 3], marker=\"*\", markersize=15, color='orange')\n",
        "        plt.plot(y_test[i, :, 2], y_test[i, :, 3], color='cyan', lw=2, label='CSTR2_Test')\n",
        "        plt.plot(y_predict[i, :, 2], y_predict[i, :, 3], color='black', lw=2, ls=':', label='CSTR2_Predicted')\n",
        "    else:\n",
        "        plt.plot(X_plot[i, 0, 0], X_plot[i, 0, 1], marker=\"*\", markersize=15, color='blue')\n",
        "        plt.plot(y_test[i, :, 0], y_test[i, :, 1], color='cyan', lw=2)\n",
        "        plt.plot(y_predict[i, :, 0], y_predict[i, :, 1], color='black', lw=2, ls=':')\n",
        "        plt.plot(X_plot[i, 0, 2], X_plot[i, 0, 3], marker=\"*\", markersize=15, color='orange')\n",
        "        plt.plot(y_test[i, :, 2], y_test[i, :, 3], color='cyan', lw=2)\n",
        "        plt.plot(y_predict[i, :, 2], y_predict[i, :, 3], color='black', lw=2, ls=':')\n",
        "\n",
        "# plot stability region\n",
        "plt.plot(x_lower, y_plot, color='steelblue',label='Ωρ')\n",
        "plt.plot(x_upper, y_plot, color='steelblue')\n",
        "plt.ylim([-100, 100])\n",
        "plt.xlim([-2, 2])\n",
        "plt.ylim([-100, 100])\n",
        "plt.xlim([-2, 2])\n",
        "\n",
        "plt.xlabel(\"C_A - C_As\")\n",
        "plt.ylabel(\"T - T_s\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "G9i5SPwl_ZYc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}